{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\r\n",
    "import numpy as np\r\n",
    "from numpy.random import rand\r\n",
    "import tensorflow as tf\r\n",
    "import sys\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "def createTransform(scale=1, angle=0, x=0, y=0, p1=0, p2=0):\r\n",
    "    angle = angle/180*np.pi\r\n",
    "    return np.array([[scale*np.cos(angle), -scale*np.sin(angle), x ],\r\n",
    "                    [scale*np.sin(angle),  scale*np.cos(angle),  y ],\r\n",
    "                    [p1, p2, 1]])\r\n",
    "\r\n",
    "def random_perspective_placing(fg, bg):\r\n",
    "    bh, bw, _ = bg.shape\r\n",
    "    h, w, _ = fg.shape\r\n",
    "    dx, dy = np.random.normal(0, 1.8/3, size=2)\r\n",
    "    p1, p2 = np.random.normal(0, 0.3/3, size=2)\r\n",
    "    a = np.random.rand()*360\r\n",
    "    s = np.random.normal(0.4, 0.13 /3)\r\n",
    "    bx = np.random.normal(0, bw/3*0.1)\r\n",
    "    by = np.random.normal(0, bh/3*0.1)\r\n",
    "\r\n",
    "    DocCent = createTransform(x=-w/2, y=-h/2)\r\n",
    "    AS = createTransform(angle=a, scale=2/h)\r\n",
    "    T = createTransform(x=dx, y=dy)\r\n",
    "    P = createTransform(p1=p1, p2=p2)\r\n",
    "    S = createTransform(scale=bh*s)\r\n",
    "    BGCent = createTransform(x=bw/2+bx, y=bh/2+by)\r\n",
    "    perspective_trans = BGCent@S@P@T@AS@DocCent\r\n",
    "\r\n",
    "    input = cv2.warpPerspective(fg, perspective_trans, (bw, bh), bg, borderMode=cv2.BORDER_TRANSPARENT) \r\n",
    "    \r\n",
    "    black = np.zeros((bh, bw))\r\n",
    "    pts = np.array([[0,0,1], [w,0,1], [w,h,1], [0,h,1]]).T\r\n",
    "    pts = perspective_trans @ pts\r\n",
    "    pts = pts[:2, :] / pts[2, :]\r\n",
    "    pts = np.int32(pts.T)\r\n",
    "    output = cv2.polylines(black, [pts], isClosed=True, color=255, thickness=2)\r\n",
    "\r\n",
    "    return input, output.astype(np.uint8)\r\n",
    "\r\n",
    "def random_cut(img, w, h):\r\n",
    "    ih, iw, _ = img.shape\r\n",
    "    r1 = int(rand() * (ih-h))\r\n",
    "    r2 = r1 + h\r\n",
    "    c1 = int(rand() * (iw-w))\r\n",
    "    c2 = c1 + w\r\n",
    "    return img[r1:r2, c1:c2]\r\n",
    "\r\n",
    "def generate_edge_data(w, h):\r\n",
    "    bg_scale = 0.4\r\n",
    "    docName = np.floor(rand()*25)\r\n",
    "    bgName = np.floor(rand()*397)\r\n",
    "    doc = cv2.imread('./raw_dataset/docs/{name:.0f}.jpg'.format(name=docName))\r\n",
    "    bg = cv2.imread('./raw_dataset/backgrounds/{name:.0f}.jpg'.format(name=bgName))\r\n",
    "    bg = cv2.resize(bg, None, fx=bg_scale, fy=bg_scale)\r\n",
    "    bg = random_cut(bg, w, h)\r\n",
    "    return random_perspective_placing(doc, bg)\r\n",
    "\r\n",
    "def test(w, h):\r\n",
    "    for i in range(10):\r\n",
    "        input, output = generate_edge_data(w, h)\r\n",
    "        plt.imshow(input)\r\n",
    "        plt.show()\r\n",
    "        plt.imshow(output, cmap='gray')\r\n",
    "        plt.show()\r\n",
    "\r\n",
    "def generate(w, h, start, numb): \r\n",
    "    for i in range(start, start+numb):\r\n",
    "        input, output = generate_edge_data(w, h)\r\n",
    "        cv2.imwrite(\"./dataset/x/{i}.jpg\".format(i=i), input)\r\n",
    "        cv2.imwrite(\"./dataset/y/{i}.jpg\".format(i=i), output)\r\n",
    "\r\n",
    "        sys.stdout.write(\"\\r\" + 'Generating Images: {i}.jpg'.format(i=i))\r\n",
    "        sys.stdout.flush()\r\n",
    "        key = cv2.waitKey(1)\r\n",
    "        if key != -1 and key != 255:\r\n",
    "            cv2.destroyAllWindows()\r\n",
    "            return\r\n",
    "    print('finished')\r\n",
    "\r\n",
    "def loadData(split_rate=0.8):\r\n",
    "    def parse_files(x_fname, y_fname):\r\n",
    "        image_string = tf.io.read_file(x_fname)\r\n",
    "        image_decoded = tf.image.decode_jpeg(image_string, channels=3)\r\n",
    "        x = tf.cast(image_decoded, tf.float32) / 127.5 - 1\r\n",
    "\r\n",
    "        image_string = tf.io.read_file(y_fname)\r\n",
    "        image_decoded = tf.image.decode_jpeg(image_string, channels=1)\r\n",
    "        y = tf.cast(image_decoded, tf.float32) / 255.0\r\n",
    "\r\n",
    "        return x, y\r\n",
    "\r\n",
    "    x = tf.data.Dataset.list_files('./dataset/x/*.jpg', shuffle=False)\r\n",
    "    x = list(x.as_numpy_iterator())\r\n",
    "\r\n",
    "    y = tf.data.Dataset.list_files('./dataset/y/*.jpg', shuffle=False)\r\n",
    "    y = list(y.as_numpy_iterator())\r\n",
    "\r\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\r\n",
    "    ds = ds.shuffle(buffer_size=len(x), seed=123).map(parse_files)\r\n",
    "    # ds = ds.prefetch(buffer_size=8)\r\n",
    "    print('data size: ' + str(len(x)))\r\n",
    "\r\n",
    "    spliter = int(len(x) * split_rate)\r\n",
    "    ds_train = ds.take(spliter)\r\n",
    "    ds_test = ds.skip(spliter)\r\n",
    "    return ds_train, ds_test\r\n",
    "\r\n",
    "# test(w=512, h=512)\r\n",
    "# generate(w=512, h=512, start=0, numb=3000)\r\n",
    "# read_dataset(numb=3000)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}