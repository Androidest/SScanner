{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'Resizing' from 'tensorflow.keras.layers' (C:\\Anaconda3\\lib\\site-packages\\tensorflow\\keras\\layers\\__init__.py)","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m<ipython-input-1-f070f518d1b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mResizing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclass_balanced_sigmoid_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mImportError\u001b[0m: cannot import name 'Resizing' from 'tensorflow.keras.layers' (C:\\Anaconda3\\lib\\site-packages\\tensorflow\\keras\\layers\\__init__.py)"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import Resizing\n","\n","def class_balanced_sigmoid_cross_entropy(logits, label):\n","    y = tf.cast(label, tf.float32)\n","\n","    count_neg = tf.reduce_sum(1. - y) # the number of 0 in y\n","    count_pos = tf.reduce_sum(y) # the number of 1 in y (less than count_neg)\n","    beta = count_neg / (count_neg + count_pos)\n","\n","    pos_weight = beta / (1 - beta)\n","    cost = tf.nn.weighted_cross_entropy_with_logits(logits, y, pos_weight)\n","    cost = tf.reduce_mean(cost * (1 - beta))\n","\n","    return cost\n","\n","def showBaseSummary():\n","    base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n","                include_top=False, input_shape=(512, 512, 3))\n","    for i in range(len(base_model.layers)):\n","        l = base_model.layers[i]\n","        print(i, l.output.shape, l.name)\n","\n","def train_model(model, ds_train, ds_test=None, initial_epoch=0, epochs=50, batchSize=64):\n","    final_epoch = initial_epoch+epochs\n","    for e in range(initial_epoch, final_epoch):\n","        x = ds_train.batch(batchSize)\n","        model.fit(x=x, epochs=e+1, initial_epoch=e, verbose=1\n","            #, validation_data=ds_test, validation_freq=1\n","        )\n","\n","def predict_test(filename, maxSize=1080):\n","    image = tf.image.decode_jpeg(tf.io.read_file(filename), channels=3)\n","    image = tf.image.resize(image, (maxSize, maxSize), preserve_aspect_ratio=True)\n","    image = tf.cast(tf.reshape(image,(1)+image.shape), tf.float32) / 127.5 - 1\n","    p = model.predict(image)[0, :, :, 0]\n","    resultImg = (p > 0.5)  * 255\n","    plt.figure(figsize = (10,10))\n","    plt.imshow(resultImg, cmap='gray')\n","\n","def compile_model(input, output, lr):\n","    model = tf.keras.Model(inputs=input, outputs=output)\n","    opt_fn = tf.keras.optimizers.Adam(lr)\n","    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","    # loss_fn = class_balanced_sigmoid_cross_entropy\n","    model.compile(optimizer=opt_fn, loss=loss_fn)\n","    return model\n","\n","def create_model(lr=0.001):\n","    base_model = tf.keras.applications.mobilenet_v2.MobileNetV2( \n","        include_top=False, input_shape=(None, None, 3)) #TODO\n","    base_model.trainable = False # works only before compiling\n","\n","    input = base_model.input\n","\n","    hx = base_model.layers[26].output  # VGG:9, MobilenetV2:26,56\n","    hx = tf.keras.layers.Resizing(512, 512, interpolation='nearest')(hx)\n","    hx = tf.keras.layers.Conv2D(filters=1, kernel_size=1, padding='same')(hx)\n","    hx = tf.keras.layers.Conv2D(filters=1, kernel_size=3, padding='same')(hx)\n","    hx = tf.keras.layers.Conv2D(filters=1, kernel_size=3, padding='same')(hx)\n","    \n","    output = tf.keras.layers.Conv2D(filters=1, kernel_size=1, padding='same')(hx) # a non functional placeholder output layer\n","\n","    model = compile_model(input, output, lr)\n","    return model\n","\n","def insert_upConv(model, layer_index, lr=0.01):\n","    model.trainable = False # works only before compiling\n","    old_fused = model.layers[-1].input\n","\n","    hx = model.layers[layer_index].output  # VGG:9, MobilenetV2:26,56\n","    hx = tf.keras.layers.Resizing(512, 512, interpolation='nearest')(hx)\n","    hx = tf.keras.layers.Conv2D(filters=1, kernel_size=1, padding='same')(hx)\n","    hx = tf.keras.layers.Conv2D(filters=1, kernel_size=3, padding='same')(hx)\n","    hx = tf.keras.layers.Conv2D(filters=1, kernel_size=3, padding='same')(hx)\n","    \n","    fused = tf.concat([hx, old_fused], axis=-1)\n","    output = tf.keras.layers.Conv2D(filters=1, kernel_size=1, padding='same')(fused)\n","\n","    new_model = compile_model(model.input, output, lr)\n","    return new_model\n","\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import import_ipynb\n","from edge_data_generator import loadData, generate\n","\n","# generate(w=512, h=512, start=0, numb=3000)\n","\n","ds_train, _ = loadData(split_rate=1)\n","model = create_model(lr=0.001)\n","model = insert_upConv(model, layer_index=8, lr=0.001)\n","train_model(model, ds_train, initial_epoch=0, epochs=20, batchSize=16)\n","# model.trainable = True\n","# train_model(model, ds_train, initial_epoch=0, epochs=5, batchSize=16)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i in range(len(model.layers)):\n","    l = model.layers[i]\n","    if 'resizing' in l.name:\n","        l.target_height = 486\n","        l.target_width = 1080\n","\n","filePath = './Models/edge_detector_MobileNetV1.h5'\n","model.save(filePath, overwrite=True, include_optimizer=False)\n","predict_test(\"./raw_dataset/test.jpg\", maxSize=1080)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","filePath = './Models/edge_detector_MobileNetV1.h5'\n","model = tf.keras.models.load_model(filePath)\n","predict_test(\"./raw_dataset/test.jpg\", maxSize=1080)\n","\n","\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}