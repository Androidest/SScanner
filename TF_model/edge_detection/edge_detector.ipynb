{"cells":[{"cell_type":"code","execution_count":null,"source":["import tensorflow as tf\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","from tensorflow.keras.applications import VGG16, MobileNet, MobileNetV2, resnet50\r\n","from tensorflow.keras import layers\r\n","import cv2\r\n","\r\n","weighted_bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\r\n","def weighted_BCE(labels, logits):\r\n","    # labels = tf.cast(labels, tf.float32)\r\n","    _, h, w, _ = labels.shape\r\n","    if h == None:\r\n","        h, w = 512, 512\r\n","\r\n","    # compute pos weight mask from labels\r\n","    imgSize = h*w \r\n","    pos_mask = labels # 1 mask\r\n","    neg_mask = 1.0 - labels # 0 mask\r\n","    pos_count = tf.reduce_sum(pos_mask, axis=(1,2,3), keepdims=True) \r\n","    neg_count = imgSize - pos_count \r\n","    pos_weight = tf.math.divide_no_nan(pos_mask,pos_count) + tf.math.divide_no_nan(neg_mask, neg_count) # mask of norm weights\r\n","\r\n","    loss = weighted_bce(labels, logits, sample_weight=pos_weight) * imgSize\r\n","\r\n","    return loss\r\n","\r\n","def showBaseSummary(base):\r\n","    base_model = base(include_top=False, input_shape=(512, 512, 3))\r\n","    for i in range(len(base_model.layers)):\r\n","        l = base_model.layers[i]\r\n","        print(i, l.output.shape, l.name)\r\n","\r\n","def train_model(model, ds_train, ds_test=None, epochs=10, batchSize=32):\r\n","    for e in range(0, epochs):\r\n","        x = ds_train.shuffle(2000).batch(batchSize)\r\n","        model.fit(x=x, epochs=e+1, initial_epoch=e, verbose=1\r\n","            #, validation_data=ds_test, validation_freq=1\r\n","        )\r\n","\r\n","def fine_tune(model, lr, opt):\r\n","    model.trainable = True\r\n","    for layer in model.layers:\r\n","        if 'sscanner' not in layer.name:\r\n","            layer.trainable =  False\r\n","    \r\n","    return compile_model(model.input, model.output, lr, opt)\r\n","\r\n","def predict_test(model, filename, maxSize=1080):\r\n","    image = tf.image.decode_jpeg(tf.io.read_file(filename), channels=3)\r\n","    image = tf.image.resize(image, (maxSize, maxSize), preserve_aspect_ratio=True)\r\n","    image = tf.cast(tf.reshape(image,(1)+image.shape), tf.float32) / 127.5 - 1\r\n","    p = model.predict(image)[0, :, :, 0]\r\n","    resultImg = (p>0)  * 255\r\n","    plt.figure(figsize = (10,10))\r\n","    plt.imshow(resultImg, cmap='gray')\r\n","\r\n","    bit = resultImg.numpy()\r\n","    lines = cv2.HoughLinesP(bit, 1, np.pi / 180, 50, None, 50, 10)\r\n","    print(lines)\r\n","\r\n","def compile_model(input, output, lr, opt=\"Adam\"):\r\n","    model = tf.keras.Model(inputs=input, outputs=output)\r\n","    opt_fn = tf.keras.optimizers.Adam(lr)\r\n","    if opt == \"SGD\":\r\n","        print(\"Using SGD Optimizer\")\r\n","        opt_fn = tf.keras.optimizers.SGD(lr)\r\n","    loss_fn = weighted_BCE\r\n","    model.compile(optimizer=opt_fn, loss=loss_fn)\r\n","\r\n","    return model\r\n","\r\n","def create_model(base, layer_index, scale, lr=0.001):\r\n","    base_model = base(include_top=False, input_shape=(None, None, 3)) #TODO\r\n","    base_model.trainable = False # works only before compiling\r\n","\r\n","    input = base_model.input\r\n","    hx = base_model.layers[layer_index].output  \r\n","    hx = create_block(hx, scale)\r\n","    output = layers.Conv2D(filters=1, kernel_size=1, padding='same')(hx) # a non functional placeholder output layer\r\n","\r\n","    model = compile_model(input, output, lr)\r\n","    return model\r\n","\r\n","def insert_upsampling(model, layer_index, scale, lr=0.001):\r\n","    model.trainable = False # works only before compiling\r\n","\r\n","    old_fused = model.layers[-1].input\r\n","    hx = model.layers[layer_index].output  \r\n","    hx = create_block(hx, scale)\r\n","    fused = layers.Concatenate(axis=-1)([hx, old_fused])\r\n","    output = layers.Conv2D(filters=1, kernel_size=1, padding='same')(fused)\r\n","\r\n","    new_model = compile_model(model.input, output, lr)\r\n","    return new_model\r\n","\r\n","count = 0\r\n","def create_block(hx, scale):\r\n","    global count\r\n","    count += 1\r\n","    \r\n","    hx = layers.Conv2D(name=\"sscanner{i}_0\".format(i=count), filters=8, kernel_size=1, padding='same')(hx)\r\n","    hx = layers.BatchNormalization()(hx)\r\n","    hx = layers.ReLU()(hx)\r\n","\r\n","    hx = layers.Conv2DTranspose(name=\"sscanner{i}_1\".format(i=count), filters=1, kernel_size=2*scale, strides=scale ,padding='same')(hx)\r\n","\r\n","    hx = layers.Resizing(512, 512, interpolation='nearest')(hx)\r\n","    \r\n","    return hx\r\n","\r\n","# showBaseSummary(base=MobileNetV2)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["import import_ipynb\r\n","from edge_data_generator import loadData, generate\r\n","\r\n","# generate(w=512, h=512, start=0, numb=3000, border_width=2)\r\n","ds_train, _ = loadData(split_rate=0.3)\r\n","ds_train = ds_train.prefetch(buffer_size=8)\r\n","\r\n","# ===== VGG16 : too heavy for browser =========\r\n","    # model = create_model(base=VGG16, layer_index=13, lr=0.001)\r\n","    # train_model(model, ds_train, epochs=2, batchSize=32)\r\n","    # model = insert_upsampling(model, layer_index=9, lr=0.001)\r\n","    # train_model(model, ds_train, epochs=2, batchSize=32)\r\n","    # model = insert_upsampling(model, layer_index=5, lr=0.001)\r\n","    # train_model(model, ds_train, epochs=2, batchSize=32)\r\n","    # model = insert_upsampling(model, layer_index=2, lr=0.001)\r\n","    # train_model(model, ds_train, epochs=3, batchSize=32)\r\n","    # model = fine_tune(model, lr=0.0001)\r\n","    # train_model(model, ds_train, epochs=7, batchSize=32)\r\n","\r\n","\r\n","# ===== Mobilenet V1 ======\r\n","# model = create_model(base=MobileNet, layer_index=72, scale=16, lr=0.001)\r\n","# train_model(model, ds_train, epochs=2, batchSize=8)\r\n","# model = insert_upsampling(model, layer_index=35, scale=8, lr=0.001)\r\n","# train_model(model, ds_train, epochs=3, batchSize=8)\r\n","# model = insert_upsampling(model, layer_index=22, scale=4, lr=0.001)\r\n","# train_model(model, ds_train, epochs=3, batchSize=8)\r\n","# model = insert_upsampling(model, layer_index=9, scale=2, lr=0.001)\r\n","# train_model(model, ds_train, epochs=4, batchSize=8)\r\n","# ds_train, _ = loadData(split_rate=1)\r\n","# ds_train = ds_train.prefetch(buffer_size=32)\r\n","# model = fine_tune(model, lr=0.0001, opt=\"SGD\")\r\n","# train_model(model, ds_train, epochs=5, batchSize=32)\r\n","\r\n","# ====== Mobilenet V2 Small ======\r\n","model = create_model(base=MobileNetV2, layer_index=26, scale=4, lr=0.001) \r\n","train_model(model, ds_train, epochs=3, batchSize=8)\r\n","model = insert_upsampling(model, layer_index=8, scale=2, lr=0.001)\r\n","train_model(model, ds_train, epochs=5, batchSize=8)\r\n","ds_train, _ = loadData(split_rate=1)\r\n","ds_train = ds_train.prefetch(buffer_size=8)\r\n","model = fine_tune(model, lr=0.0001, opt=\"SGD\")\r\n","train_model(model, ds_train, epochs=10, batchSize=8)\r\n","\r\n","# ====== Mobilenet V2 Large ====== 115, 106, 97, 89, 80, 71\r\n","# model = create_model(base=MobileNetV2, layer_index=80, scale=16, lr=0.001)\r\n","# train_model(model, ds_train, epochs=2, batchSize=32)\r\n","# model = insert_upsampling(model, layer_index=53, scale=8, lr=0.001)\r\n","# train_model(model, ds_train, epochs=3, batchSize=32)\r\n","# model = insert_upsampling(model, layer_index=26, scale=4, lr=0.001)\r\n","# train_model(model, ds_train, epochs=3, batchSize=32)\r\n","# model = insert_upsampling(model, layer_index=8, scale=2, lr=0.001)\r\n","# train_model(model, ds_train, epochs=4, batchSize=32)\r\n","# ds_train, _ = loadData(split_rate=0.3)\r\n","# ds_train = ds_train.prefetch(buffer_size=32)\r\n","# model = fine_tune(model, lr=0.0001, opt=\"SGD\")\r\n","# train_model(model, ds_train, epochs=7, batchSize=32)\r\n","# model.trainable = True\r\n","# model = compile_model(model.input, model.output, 0.000001, \"Adam\")\r\n","# train_model(model, ds_train, epochs=7, batchSize=8)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":["for i in range(len(model.layers)):\r\n","    l = model.layers[i]\r\n","    if 'resizing' in l.name:\r\n","        l.target_height = 486\r\n","        l.target_width = 1080\r\n","\r\n","filePath = './Models/edge_detector_MobileNetV2.h5'\r\n","model.save(filePath, overwrite=True, include_optimizer=False)\r\n","predict_test(model, \"./raw_dataset/test.jpg\", maxSize=1080)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":12,"source":["import tensorflow as tf\r\n","import tensorflowjs as tfjs\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import cv2\r\n","\r\n","def predict_test(model, filename, maxSize=1080):\r\n","    image = tf.image.decode_jpeg(tf.io.read_file(filename), channels=3)\r\n","    image = tf.image.resize(image, (maxSize, maxSize), preserve_aspect_ratio=True)\r\n","    input = tf.cast(tf.reshape(image,(1)+image.shape), tf.float32) / 127.5 - 1\r\n","    p = model.predict(input)[0, :, :, 0]\r\n","    resultImg = (p>0)  * 255\r\n","    plt.figure(figsize = (10,10))\r\n","    plt.imshow(resultImg, cmap='gray')\r\n","\r\n","    # bit = np.uint8(resultImg)\r\n","    # lines = cv2.HoughLinesP(bit, 1, np.pi/150, 200, None, 320, 15)\r\n","    # image = np.uint8(image.numpy())\r\n","    # if lines is not None:\r\n","    #     for l in lines:\r\n","    #         l = l[0]\r\n","    #         cv2.line(image, (l[0], l[1]), (l[2], l[3]), (0,0,255), 1, cv2.LINE_AA)\r\n","    # plt.imshow(image)\r\n","\r\n","\r\n","filePath = './Models/edge_detector_MobileNetV2_0_final'\r\n","model = tf.keras.models.load_model(filePath+'.h5')\r\n","# tfjs.converters.save_keras_model(model, filePath+\"/\")\r\n","predict_test(model, \"./raw_dataset/test1.jpg\", maxSize=1080)\r\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'plt' is not defined","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-12-d02865b7d2c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# tfjs.converters.save_keras_model(model, filePath+\"/\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mpredict_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./raw_dataset/test1.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1080\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m<ipython-input-12-d02865b7d2c2>\u001b[0m in \u001b[0;36mpredict_test\u001b[1;34m(model, filename, maxSize)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mresultImg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m*\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultImg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"]}],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"orig_nbformat":4,"kernelspec":{"name":"python3","display_name":"Python 3.7.3 64-bit ('base': conda)"},"interpreter":{"hash":"97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"}}}